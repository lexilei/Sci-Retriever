{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=/home/ubuntu/Sci-Retriever:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "from retrieval import retrieval_via_pcst\n",
    "from bm25 import BM25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/ubuntu/Sci-Retriever/dataset/sampleqa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加模块路径到 sys.path\n",
    "module_path = \"/home/ubuntu/Sci-Retriever/src\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# 现在可以导入模块\n",
    "from utils.lm_modeling import load_model, load_text2embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inherit model weights from sentence-transformers/all-roberta-large-v1\n"
     ]
    }
   ],
   "source": [
    "model_name = 'sbert'\n",
    "path = 'dataset/graphs'\n",
    "model, tokenizer, device = load_model[model_name]()\n",
    "text2embedding = load_text2embedding[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_name=data['graph']\n",
    "graph = torch.load(f'/home/ubuntu/Sci-Retriever/dataset/graphs/{graph_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMS Strikes Back\n"
     ]
    }
   ],
   "source": [
    "question=data['question']\n",
    "answer=data['answer']\n",
    "print(answer)\n",
    "q_emb = text2embedding(model, tokenizer, device, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb = text2embedding(model, tokenizer, device, graph.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_emb = text2embedding(model, tokenizer, device, graph.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.x=abstract_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval import retrieval_via_pcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pcst_fast import pcst_fast\n",
    "from torch_geometric.data.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "tensor([[-0.0209,  0.0426,  0.0091,  ..., -0.0319,  0.0056,  0.0313],\n",
      "        [-0.0115,  0.0153,  0.0172,  ..., -0.0107,  0.0026,  0.0553],\n",
      "        [-0.0487,  0.0257, -0.0031,  ..., -0.0014,  0.0182,  0.0483],\n",
      "        ...,\n",
      "        [-0.0375,  0.0320,  0.0037,  ...,  0.0227,  0.0407,  0.0392],\n",
      "        [-0.0283,  0.0178,  0.0295,  ...,  0.0320,  0.0085,  0.0572],\n",
      "        [-0.0301,  0.0009, -0.0060,  ..., -0.0020,  0.0138,  0.0548]])\n"
     ]
    }
   ],
   "source": [
    "subg2=retrieval_via_pcst(graph, q_emb, topk=3, topk_e=0, cost_e=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "tensor([[-0.0209,  0.0426,  0.0091,  ..., -0.0319,  0.0056,  0.0313],\n",
      "        [-0.0115,  0.0153,  0.0172,  ..., -0.0107,  0.0026,  0.0553],\n",
      "        [-0.0487,  0.0257, -0.0031,  ..., -0.0014,  0.0182,  0.0483],\n",
      "        ...,\n",
      "        [-0.0375,  0.0320,  0.0037,  ...,  0.0227,  0.0407,  0.0392],\n",
      "        [-0.0283,  0.0178,  0.0295,  ...,  0.0320,  0.0085,  0.0572],\n",
      "        [-0.0301,  0.0009, -0.0060,  ..., -0.0020,  0.0138,  0.0548]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33248/2099389524.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  n_prizes = torch.nn.CosineSimilarity(dim=-1)(q_emb, torch.tensor(graph.x))\n"
     ]
    }
   ],
   "source": [
    "subg=retrieval_via_pcst(graph, q_emb, topk=3, topk_e=0, cost_e=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_via_pcst(graph, q_emb, topk=3, topk_e=3, cost_e=0.5):\n",
    "    c = 0.01\n",
    "    # if len(textual_nodes) == 0 or len(textual_edges) == 0:\n",
    "    #     desc = textual_nodes.to_csv(index=False) + '\\n' + textual_edges.to_csv(index=False, columns=['src', 'edge_attr', 'dst'])\n",
    "    #     graph = Data(x=graph.x, edge_index=graph.edge_index, edge_attr=graph.edge_attr, num_nodes=graph.num_nodes)\n",
    "    #     return graph, desc\n",
    "\n",
    "    root = -1  # unrooted\n",
    "    num_clusters = 1\n",
    "    pruning = 'gw'\n",
    "    verbosity_level = 0\n",
    "    if topk > 0:\n",
    "        n_prizes = torch.nn.CosineSimilarity(dim=-1)(q_emb, graph.x)\n",
    "        topk = min(topk, graph.num_nodes)\n",
    "        _, topk_n_indices = torch.topk(n_prizes, topk, largest=True)\n",
    "\n",
    "        n_prizes = torch.zeros_like(n_prizes)\n",
    "        n_prizes[topk_n_indices] = torch.arange(topk, 0, -1).float()\n",
    "    else:\n",
    "        n_prizes = torch.zeros(graph.num_nodes)\n",
    "\n",
    "    if topk_e > 0:\n",
    "        e_prizes = torch.nn.CosineSimilarity(dim=-1)(q_emb, torch.empty(0))\n",
    "        topk_e = min(topk_e, e_prizes.unique().size(0))\n",
    "\n",
    "        topk_e_values, _ = torch.topk(e_prizes.unique(), topk_e, largest=True)\n",
    "        e_prizes[e_prizes < topk_e_values[-1]] = 0.0\n",
    "        last_topk_e_value = topk_e\n",
    "        for k in range(topk_e):\n",
    "            indices = e_prizes == topk_e_values[k]\n",
    "            value = min((topk_e-k)/sum(indices), last_topk_e_value)\n",
    "            e_prizes[indices] = value\n",
    "            last_topk_e_value = value*(1-c)\n",
    "        # reduce the cost of the edges such that at least one edge is selected\n",
    "        cost_e = min(cost_e, e_prizes.max().item()*(1-c/2))\n",
    "    else:\n",
    "        e_prizes = torch.zeros(graph.num_edges)\n",
    "\n",
    "    costs = []\n",
    "    edges = []\n",
    "    vritual_n_prizes = []\n",
    "    virtual_edges = []\n",
    "    virtual_costs = []\n",
    "    mapping_n = {}\n",
    "    mapping_e = {}\n",
    "    for i, (src, dst) in enumerate(graph.edge_index.T.numpy()):\n",
    "        prize_e = e_prizes[i]\n",
    "        if prize_e <= cost_e:\n",
    "            mapping_e[len(edges)] = i\n",
    "            edges.append((src, dst))\n",
    "            costs.append(cost_e - prize_e)\n",
    "        else:\n",
    "            virtual_node_id = graph.num_nodes + len(vritual_n_prizes)\n",
    "            mapping_n[virtual_node_id] = i\n",
    "            virtual_edges.append((src, virtual_node_id))\n",
    "            virtual_edges.append((virtual_node_id, dst))\n",
    "            virtual_costs.append(0)\n",
    "            virtual_costs.append(0)\n",
    "            vritual_n_prizes.append(prize_e - cost_e)\n",
    "\n",
    "    prizes = np.concatenate([n_prizes, np.array(vritual_n_prizes)])\n",
    "    num_edges = len(edges)\n",
    "    if len(virtual_costs) > 0:\n",
    "        costs = np.array(costs+virtual_costs)\n",
    "        edges = np.array(edges+virtual_edges)\n",
    "\n",
    "    vertices, edges = pcst_fast(edges, prizes, costs, root, num_clusters, pruning, verbosity_level)\n",
    "\n",
    "    selected_nodes = vertices[vertices < graph.num_nodes]\n",
    "    selected_edges = [mapping_e[e] for e in edges if e < num_edges]\n",
    "    virtual_vertices = vertices[vertices >= graph.num_nodes]\n",
    "    if len(virtual_vertices) > 0:\n",
    "        virtual_vertices = vertices[vertices >= graph.num_nodes]\n",
    "        virtual_edges = [mapping_n[i] for i in virtual_vertices]\n",
    "        selected_edges = np.array(selected_edges+virtual_edges)\n",
    "\n",
    "    edge_index = graph.edge_index[:, selected_edges]\n",
    "    selected_nodes = np.unique(np.concatenate([selected_nodes, edge_index[0].numpy(), edge_index[1].numpy()]))\n",
    "\n",
    "    # n = textual_nodes.iloc[selected_nodes]\n",
    "    # e = textual_edges.iloc[selected_edges]\n",
    "    # desc = n.to_csv(index=False)+'\\n'+e.to_csv(index=False, columns=['src', 'edge_attr', 'dst'])\n",
    "\n",
    "    mapping = {n: i for i, n in enumerate(selected_nodes.tolist())}\n",
    "\n",
    "    x = graph.x[selected_nodes]\n",
    "    edge_attr = graph.edge_attr#[selected_edges]\n",
    "    src = [mapping[i] for i in edge_index[0].tolist()]\n",
    "    dst = [mapping[i] for i in edge_index[1].tolist()]\n",
    "    edge_index = torch.LongTensor([src, dst])\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(selected_nodes))\n",
    "\n",
    "    return data\n",
    "    # , desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(subg, f'/home/ubuntu/Sci-Retriever/dataset/retrieved/optimal_subg/sample/{index}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
